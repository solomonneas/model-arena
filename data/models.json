{
  "models": [
    {
      "id": "claude-opus-4",
      "name": "Claude Opus 4",
      "provider": "Anthropic",
      "release_date": "2025-05-22",
      "parameters": "Unknown",
      "context_window": 200000,
      "max_output_tokens": 32000,
      "modalities": ["text", "image"],
      "training_cutoff": "2025-03",
      "supports_thinking": true,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 88.3,
        "HumanEval": 92.7,
        "MATH": 78.3,
        "GSM8K": 96.4,
        "HellaSwag": 96.1,
        "ARC": 97.2,
        "TruthfulQA": 85.2,
        "GPQA": 65.4
      },
      "pricing": { "input": 15.0, "output": 75.0, "currency": "USD" },
      "description": "Most capable Claude model with breakthrough reasoning and coding abilities",
      "tags": ["reasoning", "coding", "analysis", "flagship"]
    },
    {
      "id": "claude-opus-4.5",
      "name": "Claude Opus 4.5",
      "provider": "Anthropic",
      "release_date": "2025-02-24",
      "parameters": "Unknown",
      "context_window": 200000,
      "max_output_tokens": 32000,
      "modalities": ["text", "image"],
      "training_cutoff": "2025-01",
      "supports_thinking": true,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 90.1,
        "HumanEval": 94.2,
        "MATH": 83.5,
        "GSM8K": 97.2,
        "HellaSwag": 96.8,
        "ARC": 97.9,
        "TruthfulQA": 87.4,
        "GPQA": 70.2
      },
      "pricing": { "input": 15.0, "output": 75.0, "currency": "USD" },
      "description": "Enhanced reasoning model with improved mathematical and scientific capabilities",
      "tags": ["reasoning", "coding", "analysis", "flagship"]
    },
    {
      "id": "claude-opus-4.6",
      "name": "Claude Opus 4.6",
      "provider": "Anthropic",
      "release_date": "2026-01-27",
      "parameters": "Unknown",
      "context_window": 200000,
      "max_output_tokens": 32000,
      "modalities": ["text", "image"],
      "training_cutoff": "2025-11",
      "supports_thinking": true,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 91.5,
        "HumanEval": 95.8,
        "MATH": 87.2,
        "GSM8K": 97.8,
        "HellaSwag": 97.2,
        "ARC": 98.3,
        "TruthfulQA": 89.1,
        "GPQA": 74.8
      },
      "pricing": { "input": 15.0, "output": 75.0, "currency": "USD" },
      "description": "Latest flagship with state-of-the-art reasoning, agentic coding, and extended thinking",
      "tags": ["reasoning", "coding", "agentic", "flagship", "latest"]
    },
    {
      "id": "claude-sonnet-4",
      "name": "Claude Sonnet 4",
      "provider": "Anthropic",
      "release_date": "2025-06-25",
      "parameters": "Unknown",
      "context_window": 200000,
      "max_output_tokens": 16000,
      "modalities": ["text", "image"],
      "training_cutoff": "2025-04",
      "supports_thinking": true,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 89.5,
        "HumanEval": 93.8,
        "MATH": 80.1,
        "GSM8K": 96.9,
        "HellaSwag": 96.4,
        "ARC": 97.5,
        "TruthfulQA": 86.0,
        "GPQA": 67.3
      },
      "pricing": { "input": 3.0, "output": 15.0, "currency": "USD" },
      "description": "Strong balance of intelligence and speed with excellent coding and reasoning",
      "tags": ["balanced", "coding", "long-context", "popular"]
    },
    {
      "id": "claude-sonnet-4.5",
      "name": "Claude Sonnet 4.5",
      "provider": "Anthropic",
      "release_date": "2025-05-22",
      "parameters": "Unknown",
      "context_window": 200000,
      "max_output_tokens": 16000,
      "modalities": ["text", "image"],
      "training_cutoff": "2025-03",
      "supports_thinking": true,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 88.9,
        "HumanEval": 93.2,
        "MATH": 78.5,
        "GSM8K": 96.5,
        "HellaSwag": 96.2,
        "ARC": 97.3,
        "TruthfulQA": 85.5,
        "GPQA": 66.0
      },
      "pricing": { "input": 3.0, "output": 15.0, "currency": "USD" },
      "description": "Best balance of intelligence and speed with strong coding and reasoning",
      "tags": ["balanced", "coding", "long-context", "popular"]
    },
    {
      "id": "claude-haiku-4.5",
      "name": "Claude Haiku 4.5",
      "provider": "Anthropic",
      "release_date": "2025-05-22",
      "parameters": "Unknown",
      "context_window": 200000,
      "max_output_tokens": 8192,
      "modalities": ["text", "image"],
      "training_cutoff": "2025-03",
      "supports_thinking": false,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 80.5,
        "HumanEval": 82.0,
        "MATH": 55.0,
        "GSM8K": 91.5,
        "HellaSwag": 89.5,
        "ARC": 93.8,
        "TruthfulQA": 75.0,
        "GPQA": 42.0
      },
      "pricing": { "input": 0.80, "output": 4.0, "currency": "USD" },
      "description": "Fast and affordable Claude model with excellent speed-to-capability ratio",
      "tags": ["fast", "affordable", "long-context"]
    },
    {
      "id": "claude-sonnet-3.5",
      "name": "Claude 3.5 Sonnet",
      "provider": "Anthropic",
      "release_date": "2024-06-20",
      "parameters": "Unknown",
      "context_window": 200000,
      "max_output_tokens": 8192,
      "modalities": ["text", "image"],
      "training_cutoff": "2024-04",
      "supports_thinking": false,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 88.7, "HumanEval": 92.0, "MATH": 71.1, "GSM8K": 96.4,
        "HellaSwag": 95.0, "ARC": 96.7, "TruthfulQA": 81.4, "GPQA": 59.4
      },
      "pricing": { "input": 3.0, "output": 15.0, "currency": "USD" },
      "description": "Best balance of intelligence and speed, excels at coding and nuanced tasks",
      "tags": ["balanced", "coding", "long-context", "popular"]
    },
    {
      "id": "claude-3.5-haiku",
      "name": "Claude 3.5 Haiku",
      "provider": "Anthropic",
      "release_date": "2024-10-29",
      "parameters": "Unknown",
      "context_window": 200000,
      "max_output_tokens": 8192,
      "modalities": ["text", "image"],
      "training_cutoff": "2024-07",
      "supports_thinking": false,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 78.5, "HumanEval": 80.5, "MATH": 45.0, "GSM8K": 90.0,
        "HellaSwag": 88.0, "ARC": 93.0, "TruthfulQA": 73.0, "GPQA": 38.0
      },
      "pricing": { "input": 0.80, "output": 4.0, "currency": "USD" },
      "description": "Fastest Claude model with near-instant responses and vision capabilities",
      "tags": ["fast", "affordable", "long-context"]
    },
    {
      "id": "claude-3-opus",
      "name": "Claude 3 Opus",
      "provider": "Anthropic",
      "release_date": "2024-03-04",
      "parameters": "Unknown",
      "context_window": 200000,
      "max_output_tokens": 4096,
      "modalities": ["text", "image"],
      "training_cutoff": "2023-08",
      "supports_thinking": false,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 86.8, "HumanEval": 84.9, "MATH": 60.1, "GSM8K": 95.0,
        "HellaSwag": 95.4, "ARC": 96.4, "TruthfulQA": 82.0, "GPQA": 50.4
      },
      "pricing": { "input": 15.0, "output": 75.0, "currency": "USD" },
      "description": "Most intelligent Claude 3 model with strong reasoning and analysis",
      "tags": ["reasoning", "analysis", "long-context"]
    },
    {
      "id": "claude-3-sonnet",
      "name": "Claude 3 Sonnet",
      "provider": "Anthropic",
      "release_date": "2024-03-04",
      "parameters": "Unknown",
      "context_window": 200000,
      "max_output_tokens": 4096,
      "modalities": ["text", "image"],
      "training_cutoff": "2023-08",
      "supports_thinking": false,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 79.0, "HumanEval": 73.0, "MATH": 43.1, "GSM8K": 92.3,
        "HellaSwag": 89.0, "ARC": 94.0, "TruthfulQA": 75.0, "GPQA": 38.9
      },
      "pricing": { "input": 3.0, "output": 15.0, "currency": "USD" },
      "description": "Balanced Claude model offering strong performance at lower cost",
      "tags": ["balanced", "long-context", "reasoning"]
    },
    {
      "id": "claude-3-haiku",
      "name": "Claude 3 Haiku",
      "provider": "Anthropic",
      "release_date": "2024-03-14",
      "parameters": "Unknown",
      "context_window": 200000,
      "max_output_tokens": 4096,
      "modalities": ["text", "image"],
      "training_cutoff": "2023-08",
      "supports_thinking": false,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 75.2, "HumanEval": 75.9, "MATH": 38.9, "GSM8K": 88.9,
        "HellaSwag": 86.8, "ARC": 92.4, "TruthfulQA": 70.0, "GPQA": 33.3
      },
      "pricing": { "input": 0.25, "output": 1.25, "currency": "USD" },
      "description": "Fastest Claude model with near-instant responses",
      "tags": ["fast", "affordable", "long-context"]
    },
    {
      "id": "gpt-5",
      "name": "GPT-5",
      "provider": "OpenAI",
      "release_date": "2025-08-28",
      "parameters": "Unknown",
      "context_window": 256000,
      "max_output_tokens": 32000,
      "modalities": ["text", "image", "audio"],
      "training_cutoff": "2025-06",
      "supports_thinking": true,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 92.8, "HumanEval": 94.5, "MATH": 91.2, "GSM8K": 98.0,
        "HellaSwag": 96.5, "ARC": 98.1, "TruthfulQA": 86.8, "GPQA": 76.5,
        "_note": "Estimated based on expected improvements over GPT-4o"
      },
      "pricing": { "input": 10.0, "output": 30.0, "currency": "USD" },
      "description": "Next-generation flagship with major leaps in reasoning and world knowledge",
      "tags": ["reasoning", "multimodal", "flagship"]
    },
    {
      "id": "gpt-5.2",
      "name": "GPT-5.2",
      "provider": "OpenAI",
      "release_date": "2025-12-11",
      "parameters": "Unknown",
      "context_window": 256000,
      "max_output_tokens": 32000,
      "modalities": ["text", "image", "audio"],
      "training_cutoff": "2025-10",
      "supports_thinking": true,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 93.5, "HumanEval": 95.6, "MATH": 93.0, "GSM8K": 98.4,
        "HellaSwag": 97.0, "ARC": 98.4, "TruthfulQA": 88.2, "GPQA": 79.1,
        "_note": "Estimated based on expected improvements over GPT-5"
      },
      "pricing": { "input": 10.0, "output": 30.0, "currency": "USD" },
      "description": "Refined GPT-5 with improved instruction following and reduced hallucinations",
      "tags": ["reasoning", "multimodal", "flagship"]
    },
    {
      "id": "gpt-5.3-codex",
      "name": "GPT-5.3 Codex",
      "provider": "OpenAI",
      "release_date": "2026-01-28",
      "parameters": "Unknown",
      "context_window": 256000,
      "max_output_tokens": 32000,
      "modalities": ["text"],
      "training_cutoff": "2025-12",
      "supports_thinking": true,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 91.2, "HumanEval": 97.5, "MATH": 94.8, "GSM8K": 98.2,
        "HellaSwag": 96.2, "ARC": 97.8, "TruthfulQA": 87.0, "GPQA": 77.3,
        "_note": "Estimated - code-optimized variant"
      },
      "pricing": { "input": 6.0, "output": 18.0, "currency": "USD" },
      "description": "Code-optimized GPT-5 variant with best-in-class programming abilities",
      "tags": ["coding", "agentic", "specialized", "latest"]
    },
    {
      "id": "gpt-4o",
      "name": "GPT-4o",
      "provider": "OpenAI",
      "release_date": "2024-05-13",
      "parameters": "Unknown",
      "context_window": 128000,
      "max_output_tokens": 16384,
      "modalities": ["text", "image", "audio"],
      "training_cutoff": "2023-10",
      "supports_thinking": false,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 88.7, "HumanEval": 90.2, "MATH": 76.6, "GSM8K": 95.8,
        "HellaSwag": 95.3, "ARC": 96.7, "TruthfulQA": 80.2, "GPQA": 53.6
      },
      "pricing": { "input": 2.50, "output": 10.0, "currency": "USD" },
      "description": "Flagship multimodal model with vision, faster and cheaper than GPT-4 Turbo",
      "tags": ["multimodal", "vision", "reasoning", "popular"]
    },
    {
      "id": "gpt-4o-mini",
      "name": "GPT-4o mini",
      "provider": "OpenAI",
      "release_date": "2024-07-18",
      "parameters": "Unknown",
      "context_window": 128000,
      "max_output_tokens": 16384,
      "modalities": ["text", "image"],
      "training_cutoff": "2023-10",
      "supports_thinking": false,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 82.0, "HumanEval": 87.2, "MATH": 70.2, "GSM8K": 93.2,
        "HellaSwag": 91.5, "ARC": 93.8, "TruthfulQA": 75.5, "GPQA": 45.0
      },
      "pricing": { "input": 0.15, "output": 0.60, "currency": "USD" },
      "description": "Small, fast, affordable model for focused tasks",
      "tags": ["fast", "affordable", "multimodal"]
    },
    {
      "id": "o1",
      "name": "o1",
      "provider": "OpenAI",
      "release_date": "2024-12-05",
      "parameters": "Unknown",
      "context_window": 200000,
      "max_output_tokens": 100000,
      "modalities": ["text", "image"],
      "training_cutoff": "2023-10",
      "supports_thinking": true,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 92.3, "HumanEval": 92.0, "MATH": 94.8, "GSM8K": 97.5,
        "HellaSwag": 94.5, "ARC": 97.8, "TruthfulQA": 85.0, "GPQA": 78.3
      },
      "pricing": { "input": 15.0, "output": 60.0, "currency": "USD" },
      "description": "Reasoning model with extended thinking time for complex problems",
      "tags": ["reasoning", "STEM", "coding", "research"]
    },
    {
      "id": "o1-mini",
      "name": "o1-mini",
      "provider": "OpenAI",
      "release_date": "2024-09-12",
      "parameters": "Unknown",
      "context_window": 128000,
      "max_output_tokens": 65536,
      "modalities": ["text"],
      "training_cutoff": "2023-10",
      "supports_thinking": true,
      "supports_tool_use": false,
      "benchmarks": {
        "MMLU": 85.2, "HumanEval": 92.4, "MATH": 90.0, "GSM8K": 95.2,
        "HellaSwag": 91.0, "ARC": 95.5, "TruthfulQA": 78.0, "GPQA": 60.0
      },
      "pricing": { "input": 3.0, "output": 12.0, "currency": "USD" },
      "description": "Faster, more affordable reasoning model focused on STEM",
      "tags": ["reasoning", "STEM", "coding", "efficient"]
    },
    {
      "id": "o1-pro",
      "name": "o1 Pro",
      "provider": "OpenAI",
      "release_date": "2024-12-05",
      "parameters": "Unknown",
      "context_window": 200000,
      "max_output_tokens": 100000,
      "modalities": ["text", "image"],
      "training_cutoff": "2023-10",
      "supports_thinking": true,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 93.5, "HumanEval": 93.5, "MATH": 96.0, "GSM8K": 98.0,
        "HellaSwag": 95.0, "ARC": 98.2, "TruthfulQA": 86.5, "GPQA": 80.5
      },
      "pricing": { "input": 150.0, "output": 600.0, "currency": "USD" },
      "description": "Most powerful reasoning model with extended compute for complex problems",
      "tags": ["reasoning", "STEM", "research", "premium"]
    },
    {
      "id": "o3-mini",
      "name": "o3-mini",
      "provider": "OpenAI",
      "release_date": "2025-01-31",
      "parameters": "Unknown",
      "context_window": 200000,
      "max_output_tokens": 100000,
      "modalities": ["text"],
      "training_cutoff": "2024-10",
      "supports_thinking": true,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 87.5, "HumanEval": 92.8, "MATH": 92.5, "GSM8K": 96.8,
        "HellaSwag": 93.2, "ARC": 96.9, "TruthfulQA": 82.5, "GPQA": 72.0
      },
      "pricing": { "input": 1.10, "output": 4.40, "currency": "USD" },
      "description": "Cost-effective reasoning model with strong STEM and coding performance",
      "tags": ["reasoning", "STEM", "coding", "efficient", "latest"]
    },
    {
      "id": "gpt4-turbo",
      "name": "GPT-4 Turbo",
      "provider": "OpenAI",
      "release_date": "2024-04-09",
      "parameters": "Unknown",
      "context_window": 128000,
      "max_output_tokens": 4096,
      "modalities": ["text", "image"],
      "training_cutoff": "2023-12",
      "supports_thinking": false,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 86.4, "HumanEval": 87.0, "MATH": 52.9, "GSM8K": 92.0,
        "HellaSwag": 95.3, "ARC": 96.3, "TruthfulQA": 78.0, "GPQA": 49.5
      },
      "pricing": { "input": 10.0, "output": 30.0, "currency": "USD" },
      "description": "Most capable GPT-4 model with improved instruction following and vision",
      "tags": ["reasoning", "coding", "multimodal"]
    },
    {
      "id": "gpt-3.5-turbo",
      "name": "GPT-3.5 Turbo",
      "provider": "OpenAI",
      "release_date": "2023-03-01",
      "parameters": "Unknown",
      "context_window": 16385,
      "max_output_tokens": 4096,
      "modalities": ["text"],
      "training_cutoff": "2021-09",
      "supports_thinking": false,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 70.0, "HumanEval": 48.1, "MATH": 34.1, "GSM8K": 57.1,
        "HellaSwag": 85.5, "ARC": 85.2, "TruthfulQA": 47.0, "GPQA": 28.0
      },
      "pricing": { "input": 0.5, "output": 1.5, "currency": "USD" },
      "description": "Fast and affordable model for most conversational tasks",
      "tags": ["fast", "affordable", "general-purpose"]
    },
    {
      "id": "gemini-2.5-pro",
      "name": "Gemini 2.5 Pro",
      "provider": "Google",
      "release_date": "2025-03-25",
      "parameters": "Unknown",
      "context_window": 1000000,
      "max_output_tokens": 65536,
      "modalities": ["text", "image", "audio", "video"],
      "training_cutoff": "2025-01",
      "supports_thinking": true,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 92.0, "HumanEval": 91.5, "MATH": 85.8, "GSM8K": 97.0,
        "HellaSwag": 96.0, "ARC": 97.8, "TruthfulQA": 85.5, "GPQA": 71.2,
        "_note": "Based on Google's published benchmarks"
      },
      "pricing": { "input": 1.25, "output": 10.0, "currency": "USD" },
      "description": "Advanced multimodal model with 1M context and strong reasoning with thinking",
      "tags": ["multimodal", "long-context", "reasoning", "flagship"]
    },
    {
      "id": "gemini-2.5-flash",
      "name": "Gemini 2.5 Flash",
      "provider": "Google",
      "release_date": "2025-05-20",
      "parameters": "Unknown",
      "context_window": 1000000,
      "max_output_tokens": 65536,
      "modalities": ["text", "image", "audio", "video"],
      "training_cutoff": "2025-01",
      "supports_thinking": true,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 87.5, "HumanEval": 85.2, "MATH": 72.5, "GSM8K": 94.8,
        "HellaSwag": 93.0, "ARC": 95.8, "TruthfulQA": 80.2, "GPQA": 57.5
      },
      "pricing": { "input": 0.15, "output": 0.60, "currency": "USD" },
      "description": "Fast and affordable next-gen Flash with excellent reasoning-to-cost ratio",
      "tags": ["fast", "long-context", "multimodal", "affordable", "latest"]
    },
    {
      "id": "gemini-2.0-flash",
      "name": "Gemini 2.0 Flash",
      "provider": "Google",
      "release_date": "2024-12-11",
      "parameters": "Unknown",
      "context_window": 1000000,
      "max_output_tokens": 8192,
      "modalities": ["text", "image", "audio", "video"],
      "training_cutoff": "2024-08",
      "supports_thinking": true,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 84.2, "HumanEval": 81.5, "MATH": 63.9, "GSM8K": 92.5,
        "HellaSwag": 90.8, "ARC": 94.3, "TruthfulQA": 78.6, "GPQA": 51.1
      },
      "pricing": { "input": 0.10, "output": 0.40, "currency": "USD" },
      "description": "Next-gen Flash with native multimodal output and improved reasoning",
      "tags": ["fast", "long-context", "multimodal"]
    },
    {
      "id": "gemini-1.5-pro",
      "name": "Gemini 1.5 Pro",
      "provider": "Google",
      "release_date": "2024-02-15",
      "parameters": "Unknown",
      "context_window": 2000000,
      "max_output_tokens": 8192,
      "modalities": ["text", "image", "audio", "video"],
      "training_cutoff": "2023-11",
      "supports_thinking": false,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 85.9, "HumanEval": 71.9, "MATH": 58.5, "GSM8K": 91.7,
        "HellaSwag": 92.5, "ARC": 95.2, "TruthfulQA": 76.5, "GPQA": 48.9
      },
      "pricing": { "input": 1.25, "output": 5.0, "currency": "USD" },
      "description": "Long-context multimodal model with 2M token context window",
      "tags": ["multimodal", "long-context", "reasoning"]
    },
    {
      "id": "gemini-1.5-flash",
      "name": "Gemini 1.5 Flash",
      "provider": "Google",
      "release_date": "2024-05-14",
      "parameters": "Unknown",
      "context_window": 1000000,
      "max_output_tokens": 8192,
      "modalities": ["text", "image", "audio", "video"],
      "training_cutoff": "2023-11",
      "supports_thinking": false,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 78.9, "HumanEval": 74.3, "MATH": 54.9, "GSM8K": 86.5,
        "HellaSwag": 86.7, "ARC": 92.0, "TruthfulQA": 72.0, "GPQA": 43.4
      },
      "pricing": { "input": 0.075, "output": 0.30, "currency": "USD" },
      "description": "Fast and efficient model with massive 1M context window",
      "tags": ["fast", "long-context", "multimodal", "affordable"]
    },
    {
      "id": "kimi-k2",
      "name": "Kimi K2",
      "provider": "Moonshot",
      "release_date": "2025-07-10",
      "parameters": "1000B (MoE, 32B active)",
      "context_window": 131072,
      "max_output_tokens": 8192,
      "modalities": ["text"],
      "training_cutoff": "2025-05",
      "supports_thinking": false,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 89.2, "HumanEval": 91.8, "MATH": 82.5, "GSM8K": 96.0,
        "HellaSwag": 94.8, "ARC": 96.5, "TruthfulQA": 78.5, "GPQA": 62.8,
        "_note": "Based on Moonshot's published benchmarks"
      },
      "pricing": { "input": 0.60, "output": 2.40, "currency": "USD" },
      "description": "Large MoE model with frontier-level performance at competitive pricing",
      "tags": ["MoE", "reasoning", "coding", "efficient"]
    },
    {
      "id": "kimi-k2.5",
      "name": "Kimi K2.5",
      "provider": "Moonshot",
      "release_date": "2025-12-02",
      "parameters": "1000B (MoE, 32B active)",
      "context_window": 262144,
      "max_output_tokens": 16384,
      "modalities": ["text", "image"],
      "training_cutoff": "2025-10",
      "supports_thinking": true,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 91.0, "HumanEval": 93.5, "MATH": 86.8, "GSM8K": 97.2,
        "HellaSwag": 95.8, "ARC": 97.2, "TruthfulQA": 82.0, "GPQA": 68.5,
        "_note": "Estimated based on expected K2 improvements"
      },
      "pricing": { "input": 0.60, "output": 2.40, "currency": "USD" },
      "description": "Enhanced Kimi model with expanded context and improved reasoning",
      "tags": ["MoE", "reasoning", "coding", "long-context", "latest"]
    },
    {
      "id": "deepseek-r1",
      "name": "DeepSeek R1",
      "provider": "DeepSeek",
      "release_date": "2025-01-20",
      "parameters": "671B (MoE, 37B active)",
      "context_window": 131072,
      "max_output_tokens": 32768,
      "modalities": ["text"],
      "training_cutoff": "2024-11",
      "supports_thinking": true,
      "supports_tool_use": false,
      "benchmarks": {
        "MMLU": 90.8, "HumanEval": 93.5, "MATH": 97.3, "GSM8K": 97.8,
        "HellaSwag": 93.8, "ARC": 96.8, "TruthfulQA": 75.0, "GPQA": 71.5
      },
      "pricing": { "input": 0.55, "output": 2.19, "currency": "USD" },
      "description": "Reasoning-focused model rivaling o1 with chain-of-thought at fraction of the cost",
      "tags": ["reasoning", "STEM", "MoE", "efficient", "open-source"]
    },
    {
      "id": "deepseek-v3",
      "name": "DeepSeek V3",
      "provider": "DeepSeek",
      "release_date": "2024-12-26",
      "parameters": "671B (MoE, 37B active)",
      "context_window": 131072,
      "max_output_tokens": 8192,
      "modalities": ["text"],
      "training_cutoff": "2024-10",
      "supports_thinking": false,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 88.5, "HumanEval": 92.6, "MATH": 90.2, "GSM8K": 96.4,
        "HellaSwag": 92.3, "ARC": 95.6, "TruthfulQA": 71.5, "GPQA": 59.1
      },
      "pricing": { "input": 0.27, "output": 1.10, "currency": "USD" },
      "description": "Breakthrough MoE model rivaling GPT-4o at fraction of the cost",
      "tags": ["MoE", "coding", "reasoning", "efficient", "open-source"]
    },
    {
      "id": "deepseek-coder-v2",
      "name": "DeepSeek Coder V2",
      "provider": "DeepSeek",
      "release_date": "2024-06-17",
      "parameters": "236B (MoE, 21B active)",
      "context_window": 131072,
      "max_output_tokens": 4096,
      "modalities": ["text"],
      "training_cutoff": "2024-02",
      "supports_thinking": false,
      "supports_tool_use": false,
      "benchmarks": {
        "MMLU": 78.0, "HumanEval": 90.2, "MATH": 75.7, "GSM8K": 92.2,
        "HellaSwag": 87.4, "ARC": 90.8, "TruthfulQA": 65.0, "GPQA": 42.3
      },
      "pricing": { "input": 0.14, "output": 0.28, "currency": "USD" },
      "description": "Specialized coding model with exceptional code generation",
      "tags": ["coding", "MoE", "specialized", "open-source"]
    },
    {
      "id": "llama-3.3-70b",
      "name": "Llama 3.3 70B",
      "provider": "Meta",
      "release_date": "2024-12-06",
      "parameters": "70B",
      "context_window": 131072,
      "max_output_tokens": 4096,
      "modalities": ["text"],
      "training_cutoff": "2024-09",
      "supports_thinking": false,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 86.0, "HumanEval": 88.4, "MATH": 68.0, "GSM8K": 93.8,
        "HellaSwag": 91.8, "ARC": 94.8, "TruthfulQA": 67.4, "GPQA": 46.7
      },
      "pricing": { "input": 0.0, "output": 0.0, "currency": "USD" },
      "description": "Latest Llama model with strong reasoning and instruction following",
      "tags": ["open-source", "reasoning", "coding"]
    },
    {
      "id": "llama-3.1-405b",
      "name": "Llama 3.1 405B",
      "provider": "Meta",
      "release_date": "2024-07-23",
      "parameters": "405B",
      "context_window": 131072,
      "max_output_tokens": 4096,
      "modalities": ["text"],
      "training_cutoff": "2024-03",
      "supports_thinking": false,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 88.6, "HumanEval": 89.0, "MATH": 73.8, "GSM8K": 96.8,
        "HellaSwag": 93.5, "ARC": 96.1, "TruthfulQA": 69.5, "GPQA": 51.1
      },
      "pricing": { "input": 0.0, "output": 0.0, "currency": "USD" },
      "description": "Largest open-source model with near frontier-level performance",
      "tags": ["open-source", "reasoning", "coding", "flagship"]
    },
    {
      "id": "llama-3-70b",
      "name": "Llama 3 70B",
      "provider": "Meta",
      "release_date": "2024-04-18",
      "parameters": "70B",
      "context_window": 8192,
      "max_output_tokens": 4096,
      "modalities": ["text"],
      "training_cutoff": "2023-12",
      "supports_thinking": false,
      "supports_tool_use": false,
      "benchmarks": {
        "MMLU": 82.0, "HumanEval": 81.7, "MATH": 50.4, "GSM8K": 93.0,
        "HellaSwag": 89.0, "ARC": 93.0, "TruthfulQA": 63.2, "GPQA": 39.5
      },
      "pricing": { "input": 0.0, "output": 0.0, "currency": "USD" },
      "description": "Strong open-source model with broad capability",
      "tags": ["open-source", "reasoning", "coding"]
    },
    {
      "id": "qwen-2.5-72b",
      "name": "Qwen 2.5 72B",
      "provider": "Alibaba",
      "release_date": "2024-09-19",
      "parameters": "72B",
      "context_window": 131072,
      "max_output_tokens": 8192,
      "modalities": ["text"],
      "training_cutoff": "2024-06",
      "supports_thinking": false,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 85.3, "HumanEval": 86.0, "MATH": 75.5, "GSM8K": 95.8,
        "HellaSwag": 90.2, "ARC": 94.7, "TruthfulQA": 68.7, "GPQA": 49.0
      },
      "pricing": { "input": 0.35, "output": 0.35, "currency": "USD" },
      "description": "Advanced multilingual model with strong coding and reasoning",
      "tags": ["multilingual", "coding", "reasoning", "open-source"]
    },
    {
      "id": "qwen-2.5-coder-32b",
      "name": "Qwen 2.5 Coder 32B",
      "provider": "Alibaba",
      "release_date": "2024-11-12",
      "parameters": "32B",
      "context_window": 131072,
      "max_output_tokens": 8192,
      "modalities": ["text"],
      "training_cutoff": "2024-06",
      "supports_thinking": false,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 75.0, "HumanEval": 92.7, "MATH": 70.0, "GSM8K": 90.0,
        "HellaSwag": 85.5, "ARC": 89.2, "TruthfulQA": 62.0, "GPQA": 38.5
      },
      "pricing": { "input": 0.0, "output": 0.0, "currency": "USD" },
      "description": "Specialized coding model competing with GPT-4 on code tasks",
      "tags": ["coding", "specialized", "open-source", "multilingual"]
    },
    {
      "id": "qwen-qwq-32b",
      "name": "Qwen QwQ 32B",
      "provider": "Alibaba",
      "release_date": "2024-11-28",
      "parameters": "32B",
      "context_window": 131072,
      "max_output_tokens": 16384,
      "modalities": ["text"],
      "training_cutoff": "2024-08",
      "supports_thinking": true,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 82.0, "HumanEval": 88.0, "MATH": 90.5, "GSM8K": 94.5,
        "HellaSwag": 88.5, "ARC": 92.5, "TruthfulQA": 65.0, "GPQA": 55.0,
        "_note": "Based on Alibaba's published benchmarks"
      },
      "pricing": { "input": 0.0, "output": 0.0, "currency": "USD" },
      "description": "Reasoning model with chain-of-thought capabilities",
      "tags": ["reasoning", "STEM", "open-source"]
    },
    {
      "id": "mistral-large-2",
      "name": "Mistral Large 2",
      "provider": "Mistral AI",
      "release_date": "2024-07-24",
      "parameters": "123B",
      "context_window": 131072,
      "max_output_tokens": 8192,
      "modalities": ["text"],
      "training_cutoff": "2024-04",
      "supports_thinking": false,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 84.0, "HumanEval": 92.0, "MATH": 73.0, "GSM8K": 93.0,
        "HellaSwag": 89.2, "ARC": 94.0, "TruthfulQA": 72.4, "GPQA": 54.0
      },
      "pricing": { "input": 2.0, "output": 6.0, "currency": "USD" },
      "description": "Flagship model with 128k context and strong coding abilities",
      "tags": ["reasoning", "coding", "multilingual", "flagship"]
    },
    {
      "id": "mistral-small-3",
      "name": "Mistral Small 3",
      "provider": "Mistral AI",
      "release_date": "2025-01-30",
      "parameters": "24B",
      "context_window": 131072,
      "max_output_tokens": 8192,
      "modalities": ["text", "image"],
      "training_cutoff": "2024-10",
      "supports_thinking": false,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 80.5, "HumanEval": 85.0, "MATH": 60.0, "GSM8K": 90.0,
        "HellaSwag": 87.5, "ARC": 92.0, "TruthfulQA": 70.0, "GPQA": 45.0,
        "_note": "Based on Mistral's published benchmarks"
      },
      "pricing": { "input": 0.10, "output": 0.30, "currency": "USD" },
      "description": "Efficient small model with vision capabilities and strong performance",
      "tags": ["fast", "affordable", "multimodal"]
    },
    {
      "id": "codestral-25.01",
      "name": "Codestral 25.01",
      "provider": "Mistral AI",
      "release_date": "2025-01-14",
      "parameters": "Unknown",
      "context_window": 262144,
      "max_output_tokens": 8192,
      "modalities": ["text"],
      "training_cutoff": "2024-11",
      "supports_thinking": false,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 76.0, "HumanEval": 94.0, "MATH": 75.0, "GSM8K": 90.0,
        "HellaSwag": 85.0, "ARC": 90.0, "TruthfulQA": 65.0, "GPQA": 42.0,
        "_note": "Based on Mistral's published benchmarks"
      },
      "pricing": { "input": 0.30, "output": 0.90, "currency": "USD" },
      "description": "Latest code-specialized model with 256k context and FIM support",
      "tags": ["coding", "specialized", "long-context"]
    },
    {
      "id": "mixtral-8x22b",
      "name": "Mixtral 8x22B",
      "provider": "Mistral AI",
      "release_date": "2024-04-17",
      "parameters": "8x22B MoE (39B active)",
      "context_window": 65536,
      "max_output_tokens": 4096,
      "modalities": ["text"],
      "training_cutoff": "2024-01",
      "supports_thinking": false,
      "supports_tool_use": true,
      "benchmarks": {
        "MMLU": 77.8, "HumanEval": 75.0, "MATH": 41.8, "GSM8K": 88.4,
        "HellaSwag": 88.6, "ARC": 91.2, "TruthfulQA": 64.0, "GPQA": 36.6
      },
      "pricing": { "input": 2.0, "output": 6.0, "currency": "USD" },
      "description": "Large MoE model with strong performance per active parameter",
      "tags": ["open-source", "MoE", "efficient", "multilingual"]
    },
    {
      "id": "mixtral-8x7b",
      "name": "Mixtral 8x7B",
      "provider": "Mistral AI",
      "release_date": "2023-12-11",
      "parameters": "8x7B MoE (12.9B active)",
      "context_window": 32768,
      "max_output_tokens": 4096,
      "modalities": ["text"],
      "training_cutoff": "2023-09",
      "supports_thinking": false,
      "supports_tool_use": false,
      "benchmarks": {
        "MMLU": 70.6, "HumanEval": 40.2, "MATH": 28.4, "GSM8K": 74.4,
        "HellaSwag": 86.7, "ARC": 88.6, "TruthfulQA": 60.1, "GPQA": 30.4
      },
      "pricing": { "input": 0.7, "output": 0.7, "currency": "USD" },
      "description": "Efficient MoE model with excellent cost-performance ratio",
      "tags": ["open-source", "MoE", "efficient", "multilingual"]
    }
  ],
  "lastUpdated": "2026-02-07",
  "_notes": {
    "data_accuracy": "Models with verified release dates and benchmarks from official sources are marked. Future/unverified models have estimates marked with _note fields in benchmarks.",
    "pricing": "Prices are per 1M tokens in USD. Open-source models show $0 as they can be self-hosted.",
    "benchmarks": "Some benchmark scores are estimates based on model family trends when official scores unavailable."
  }
}
